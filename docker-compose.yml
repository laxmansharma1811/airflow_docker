version: '3'

services:
  jupyter:
    image: jupyter/scipy-notebook:latest
    ports:
      - "8888:8888"
    volumes:
      - ./notebooks:/home/jovyan/work  # Mount local directory for notebooks
    environment:
      JUPYTER_ENABLE_LAB: "yes"
    networks:
      - kafka-net
  
  kafka:
    image: wurstmeister/kafka:latest
    ports:
      - "9092:9092"
    environment:
      KAFKA_ADVERTISED_HOST_NAME: kafka
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_CREATE_TOPICS: "test-topic:1:1"  # Replace with your desired topics
    depends_on:
      - zookeeper
    networks:
      - kafka-net

  zookeeper:
    image: wurstmeister/zookeeper:latest
    ports:
      - "2181:2181"
    networks:
      - kafka-net

  nifi:
    image: apache/nifi:latest
    ports:
      - "8443:8443"
    environment:
      - NIFI_WEB_HTTP_PORT=8443
    volumes:
      - ./nifi:/opt/nifi/nifi-current/postgresdriver
    networks:
      - kafka-net

  postgres:
    image: postgres:12
    environment:
      - POSTGRES_USER=airflow
      - POSTGRES_PASSWORD=airflow
      - POSTGRES_DB=airflow
    ports:
      - "5434:5432"
    volumes:
      - ./postgres_data:/postgres_data
    networks:
      - kafka-net

  pgadmin:
    image: dpage/pgadmin4
    environment:
      - PGADMIN_DEFAULT_EMAIL=admin@example.com
      - PGADMIN_DEFAULT_PASSWORD=admin
    ports:
      - "5050:80"  # Map container's port 80 to host's port 5050
    networks:
      - kafka-net

  scheduler:
    build:
      context: .
      dockerfile: ./airflow/Dockerfile
    entrypoint: ./scripts/airflow-entrypoint.sh
    command: scheduler
    restart: on-failure
    depends_on:
      - postgres
    environment:
      - AIRFLOW__CORE__LOAD_DEFAULT_CONNECTIONS=False
      - AIRFLOW__CORE__SQL_ALCHEMY_CONN=postgres+psycopg2://airflow:airflow@postgres:5432/airflow
      - AIRFLOW__CORE__FERNET_KEY=81HqDtbqAywKSOumSha3BhWNOdQ26slT6K0YaZeZyPs=
      - AIRFLOW_CONN_METADATA_DB=postgres+psycopg2://airflow:airflow@postgres:5432/airflow
      - AIRFLOW_VAR__METADATA_DB_SCHEMA=airflow
      - AIRFLOW__SCHEDULER__SCHEDULER_HEARTBEAT_SEC=5
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
    env_file:
      - .env
    ports:
      - "8794:8793"
    volumes:
      - ./dags:/opt/airflow/dags
      - ./airflow-logs:/opt/airflow/logs
      - ./scripts:/opt/airflow/scripts
    healthcheck:
      test: ["CMD-SHELL", "[ -f /usr/local/airflow/airflow-webserver.pid ]"]
      interval: 30s
      timeout: 30s
      retries: 2
    networks:
      - kafka-net

  webserver:
    hostname: webserver
    build:
      context: .
      dockerfile: ./airflow/Dockerfile
    entrypoint: ./scripts/airflow-entrypoint.sh
    command: webserver
    restart: always
    depends_on:
      - postgres
    env_file:
      - .env
    environment:
      - AIRFLOW__CORE__LOAD_DEFAULT_CONNECTIONS=False
      - AIRFLOW__CORE__SQL_ALCHEMY_CONN=postgres+psycopg2://airflow:airflow@postgres:5432/airflow
      - AIRFLOW__CORE__FERNET_KEY=81HqDtbqAywKSOumSha3BhWNOdQ26slT6K0YaZeZyPs=
      - AIRFLOW_CONN_METADATA_DB=postgres+psycopg2://airflow:airflow@postgres:5432/airflow
      - AIRFLOW_VAR__METADATA_DB_SCHEMA=airflow
      - AIRFLOW__SCHEDULER__SCHEDULER_HEARTBEAT_SEC=5
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
    volumes:
      - ./dags:/opt/airflow/dags
      - ./airflow-logs:/opt/airflow/logs
      - ./scripts:/opt/airflow/scripts
    ports:
      - "8080:8080"
    healthcheck:
      test: ["CMD-SHELL", "[ -f /usr/local/airflow/airflow-webserver.pid ]"]
      interval: 30s
      timeout: 30s
      retries: 2
    networks:
      - kafka-net

######################################################
# SPARK SERVICES
######################################################
  spark:
    image: docker.io/bitnami/spark:3.5
    environment:
      - SPARK_MODE=master
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
      - SPARK_USER=spark
      - JAVA_HOME=/opt/bitnami/java
      - SPARK_JARS_DIR=/opt/bitnami/spark/jars
    ports:
      - "8181:8080"
      - "7077:7077"
    networks:
      - kafka-net
  spark-worker:
    image: docker.io/bitnami/spark:3.5
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark:7077
      - SPARK_WORKER_MEMORY=1G
      - SPARK_WORKER_CORES=1
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
      - SPARK_USER=spark
      - SPARK_JARS_DIR=/opt/bitnami/spark/jars
      - JAVA_HOME=/opt/bitnami/java
    networks:
      - kafka-net
    ports:
      - "8082:8082"

## minio service
  minio:
      hostname: myminio
      image: quay.io/minio/minio
      restart: always
      ports:
          - "9000:9000"
          - "9001:9001"
      volumes:
          - ./miniodata:/data/
      environment:
          - MINIO_ROOT_USER=minio
          - MINIO_ROOT_PASSWORD=minio123
          - EXECUTOR=Local
      command: server /data --console-address ":9001"
      networks:
          - kafka-net

networks:
  kafka-net:
    driver: bridge
    
volumes:
  postgres-data:
  miniodata: